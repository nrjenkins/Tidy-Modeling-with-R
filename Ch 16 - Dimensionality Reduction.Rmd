---
title: 'Chapter 16: Dimensionality Reduction'
author: "Nick Jenkins"
date: '2022-04-20'
output: html_document
---

Dimensionality reduction is a good choice when you suspect that there are too many variables. 

# What Problems Can Dimensionality Reduction Solve?

Can be used either in feature engineering or in exploratory data analysis. 

Principal component analysis is one of the most straightforward methods for reducing the number of columns in the data set because it relies on linear methods and it is unsupervised. 

# A Picture is Worth a Thousand ... Beans

```{r}
library(tidymodels)
tidymodels_prefer()

library(beans)

set.seed(1601)
bean_split <- initial_split(beans, strata = class, prop = 3/4)

bean_train <- training(bean_split)
bean_test <- testing(bean_split)

set.seed(1602)
bean_val <- validation_split(bean_train, strata = class, prop = 4/5)
bean_val$splits[[1]]
```

To visually assess how well different methods perform, we can estimate the methods on the training set and display the results using the validation set. 

Since many of the shape features are probably measuring similar concepts, let's take a look at the correlation structure of the data. 

```{r}
library(corrplot)
tmwr_cols <- colorRampPalette(c("#91CBD765", "#CA225E"))

bean_train %>% 
  select(-class) %>% 
  cor() %>% 
  corrplot(col = tmwr_cols(200), tl.col = "black", method = "ellipse")
```

# A Starter Recipe

For PCA it is important to normalize all predictors. The **bestNormalize** package has a step that can enforce a symmetric distribution for the predictors. 

```{r}
library(bestNormalize)

bean_recipe <- 
  recipe(class ~ ., data = analysis(bean_val$splits[[1]])) %>% 
  step_zv(all_numeric_predictors()) %>% 
  step_orderNorm(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors())
```

# Recipes in the Wild

* `prep(recipe, training)` fits the recipe to the training set (analogous to `fit()`)
* `bake(recipe, new_data)` applies the recipe operations to `new_data` (analogus to `predict()`)

## Preparing a Recipe

Let's estimate `bean_rec` using the training set, with `prep(bean_rec)`:

```{r}
bean_recipe_trained <- prep(bean_recipe)
bean_recipe_trained
```

`prep()` has an option to save the processed data set with `retain = TRUE`.

## Baking the Recipe

```{r}
bean_validation <- bean_val$splits %>% pluck(1) %>% assessment()
bean_val_processed <- bake(bean_recipe_trained, new_data = bean_validation)

library(patchwork)
p1 <- 
  bean_validation %>% 
  ggplot(aes(x = area)) +
  geom_histogram(bins = 30, color = "white", fill = "blue", alpha = 1/3) +
  ggtitle("Original validation set data")

p2 <- 
  bean_val_processed %>% 
  ggplot(aes(x = area)) +
  geom_histogram(bins = 30, color = "white", fill = "red", alpha = 1/3) +
  ggtitle("Processed validation set data")

p1 + p2
```

# Feature Extraction Techniques

Let's write a function that will estimate the transformation and plot the resulting data in a scatter plot matrix via the **ggforce** package. 

```{r}
library(ggforce)

plot_validation_results <- function(recipe, dat = assessment(bean_val$splits[[1]])) {
  recipe %>%
    # Estimate any additional steps
    prep() %>%
    # Process the data (the validation set by default)
    bake(new_data = dat) %>%
    # Create the scatterplot matrix
    ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +
    geom_point(alpha = 0.4, size = 0.5) +
    geom_autodensity(alpha = .3) +
    facet_matrix(vars(-class), layer.diag = 2) + 
    scale_color_brewer(palette = "Dark2") + 
    scale_fill_brewer(palette = "Dark2")
}
```

## Principal Component Analysis

PCA is an unsupervised method that uses linear combinations of the predictors to define new features. These features attempt to account for as much variation as possible in the original data. We add `step_pca()` to the original recipe and use our function to visualize the results on the validation set. 

```{r}
bean_recipe_trained %>% 
  step_pca(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("Principal Component Analysis")
```

This shows that the first two components `PC1` and `PC2` do an effective job distinguishing between or separating classes. 

What factors are driving the performance of the PCA?

```{r}
library(learntidymodels)
```

## Partial Least Squares

PLS is a supervised version of PCA. It tries to find components that simultaneously maximize the variation in the predictors while also maximizing the relationship between those components and the outcome. 

```{r}
bean_recipe_trained %>% 
  step_pls(all_numeric_predictors(), num_comp = 4, outcome = "class") %>% 
  plot_validation_results() +
  ggtitle("Partial Least Squares")
```

## Independent Components Analysis

ICA is different than PCA in that it finds components that are as statistically independent from one another as possible (as opposed to being uncorrelated). It can be thought of as maximizing the "non-Gaussianity" of the ICA components, or separating information instead of compressing information like PCA. Let's use `step_ica()`:

```{r}
bean_recipe_trained %>% 
  step_ica(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("Principal Component Analysis")
```

There doesn't seem to be much separation here. 

## Uniform Manifold Approximation and Project

UMAP uses a distance-based nearest neighbor method to find local areas of the data where the data points are more likely to be related. 
```{r}
library(embed)
bean_recipe_trained %>% 
  step_umap(all_numeric_predictors(), num_comp = 4) %>% 
  plot_validation_results() +
  ggtitle("UMAP")
```

There is also a supervised version of UMAP:

```{r}
bean_recipe_trained %>% 
  step_umap(all_numeric_predictors(), num_comp = 4, outcome = "class") %>% 
  plot_validation_results() +
  ggtitle("UMAP (Supervised)")
```

UMAP can be very sensitv to tuning parameters. 

# Modeling

Both PLS and UMAP are worth investigating in conjunction with different models. 

```{r}
library(baguette)
library(discrim)

mlp_model <- 
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
  set_engine("nnet") %>% 
  set_mode("classification")

bagging_model <- 
  bag_tree() %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

fda_model <- 
  discrim_flexible(prod_degree = tune()) %>% 
  set_engine("earth")

rda_model <- 
  discrim_regularized(frac_common_cov = tune(), frac_identity = tune()) %>% 
  set_engine("klaR")

bayes_model <- 
  naive_Bayes() %>% 
  set_engine("klaR")
```

Now we need recipes. 

```{r}
bean_recipe <- 
  recipe(class ~ ., data = bean_train) %>% 
  step_zv(all_numeric_predictors()) %>% 
  step_orderNorm(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors())

pls_recipe <- 
  bean_recipe %>% 
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = tune())

umap_recipe <- 
  bean_recipe %>% 
  step_umap(all_numeric_predictors(), outcome = "class", num_comp = tune(),
            neighbors = tune(), min_dist = tune())
```

We can combine these preprocessors and models and cross them with **workflowsets**. 

```{r}
ctrl <- control_grid(parallel_over = "everything")

bean_recipe <- 
  workflow_set(
    preproc = list(basic = class ~ ., pls = pls_recipe, umap = umap_recipe),
    models = list(bayes = bayes_model, fda = fda_model, rda = rda_model,
                  bag = bagging_model, mlp = mlp_model)
  ) %>% 
  workflow_map(verbose = TRUE, seed = 1603, resamples = bean_val,
               grid = 10, metrics = metric_set(roc_auc), control = ctrl)
```

We can rank the models by their validation set estimates of the area under the ROC curve:

```{r}
library(tidyverse)
rankings <- 
  rank_results(bean_recipe, select_best = TRUE) %>% 
  mutate(method = map_chr(wflow_id, ~ str_split(.x, "_", simplify = TRUE)[1]))

tidymodels_prefer()
filter(rankings, rank <= 5) %>% select(rank, mean, model, method)

ggplot(data = rankings, 
       aes(x = rank, y = mean, color = model, shape = method)) +
  geom_point() +
  geom_text(aes(y = mean - 1/512, label = wflow_id), angle = 90, hjust = 1)
```

We'll use the RDA model with PLS features as the final model with the numerically best parameters. 

```{r}
rda_recipe <- 
  bean_recipe %>% 
  extract_workflow("pls_rda") %>% 
  finalize_workflow(bean_recipe %>% 
                      extract_workflow_set_result("pls_rda") %>% 
                      select_best(metric = "roc_auc")) %>% 
  last_fit(split = bean_split, metrics = metric_set(roc_auc))

rda_wflow_fit <- rda_recipe$.workflow[[1]]
rda_wflow_fit

collect_metrics(rda_recipe)
```

