---
title: "Chapter 8: Feature Engineering with recipes"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Feature engineering entails reformatting predictor values to make them easier for a model to use effectively. The **recipes** package can be used to combine different feature engineering and preprocessing tasks into a single object. 

```{r}
library(tidymodels)
data(ames)

ames <- mutate(ames, Sale_Price = log10(Sale_Price))

set.seed(123)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <- testing(ames_split)

lm_model <- linear_reg() %>% set_engine("lm")

lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))

lm_fit <- fit(lm_wflow, ames_train)
```

# A simple `recipe()` for the Ames Housing Data

When we fit a linear model with `lm()`:

```{r eval = FALSE}
lm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type,
   data = ames)
```

The formula proceeds with a series of steps:

1. Sale price is defined as the outcome while neighborhood, gross living area, the year built, and the building type variables are all defined as predictors. 

2. A log transformation is applied to the gross living area predictor.

3. The neighborhood and building type columns are converted from a non-numereic format to a numeric format. 

A recipe is also an object that defines a series of steps for data processing. Unlike the formula method inside a modeling function, the recipe defines the steps via `step_*()` functions without immediately executing them; it is only a specification of what should be done. Here is a recipe equivalent to the formula above that builds on the code summary:

```{r}
simple_ames <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_dummy(all_nominal_predictors())

simple_ames
```

Here are the advantages of using a recipe over a formula or raw predictors:

* These computations can be recycled across models since they are not tightly coupled to the modeling function.

* A recipe enables a broader set of data processing choices than formulas offer.

* The syntax can be very compact. 

* All data processing can be captured in a single R object instead of in scripts that are repeated, or even spread across different files

# Using Recipes

Let's use the `simple_ames` recipe to preprocess data for modeling.

```{r}
lm_wflow %>% 
  add_recipe(simple_ames)
```

That gave an error because we can only have one preprocessing method at a time. 

```{r}
lm_wflow <- 
  lm_wflow %>% 
  remove_variables() %>% 
  add_recipe(simple_ames)
lm_wflow
```

Now let's estimate the recipe and model using `fit()`:

```{r}
lm_fit <- fit(lm_wflow, ames_train)
```

The `predict()` method apples the same preprocessing that was used on the training set to the new data before passing them along to the model's `predict()` method:

```{r}
predict(lm_fit, ames_test %>% slice(1:3))
```

We can also get the bare model object or recipe with `extract_*`

```{r}
lm_fit %>% 
  extract_recipe(estimated = TRUE)

# tidy the model fit:
lm_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
```

# How Data Are Used by the `recipe()`

# Examples of `recipe()` Steps

## Encoding Qualitative Data in a Numeric Format

Transforming nominal or qualitative data so that they can be encoded or represented numerically is a very common task. `step_unknown()` can be used to change missing values to a dedicated factor level. Similarly, we can use `step_novel()` to create a new factor level that might occur with future data. 

`step_other()` can be used to analyze the frequencies of the factor levels in the training set and convert infrequently occuring values to a catch-all level of "other."

```{r}
ames %>% 
  ggplot(aes(x = Neighborhood)) +
  geom_bar() +
  coord_flip()
```

There are two neighborhoods with less than 5 properties. It is possible that no properties from those neighborhoods were included in the training set. This might be a problem for testing the model. If we ass `step_other(Neighborhood, threshold = 0.01)` to the recipe, the bottom 1% of the neighborhoods will be lumped into a new level called "other."

```{r}
simple_ames <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal_predictors())
```

## Interaction Terms

```{r}
ggplot(ames_train, aes(x = Gr_Liv_Area, y = 10^Sale_Price)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~ Bldg_Type) +
  geom_smooth(method = lm, formula = y ~ x, se = FALSE, color = "lightblue") +
  scale_x_log10() +
  scale_y_log10()
```

With the current recipe, `step_dummy()` has already created dummy variables, so the additional step is `step_interact(~ interaction terms)`.

```{r}
simple_ames <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ Gr_Liv_Area:starts_with("Bldg_Type_"))
```

## Spline Functions

Splines replace the existing numeric predictor with a set of columns that allow a model to emulate a flexible, non-linear relationship. 

```{r}
library(patchwork)
library(splines)

plot_smoother <- function(deg_free) {
  ggplot(ames_train, aes(x = Latitude, y = 10^Sale_Price)) +
    geom_point(alpha = 0.2) +
    scale_y_log10() +
    geom_smooth(method = lm,
                formula = y ~ ns(x, df = deg_free),
                color = "lightblue",
                se = FALSE) +
    labs(title = paste(deg_free, "Spline Terms"))
}

(plot_smoother(2) + plot_smoother(5)) / (plot_smoother(20) + plot_smoother(100))
```

The number of splines could be considered a turning parameter. 

In **recipes** there are multiple steps that can create these types of terms. To add a natural spline representation for this predictor:

```{r}
recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ Gr_Liv_Area:starts_with("Bldg_Type_")) %>% 
  step_ns(Latitude, deg_free = 20)
```

## Feature Extraction

Feature extraction is a common method for representing multiple features at once. PCA tries to extract as much of the original information in the predictor set as possible using a smaller number of features. In the Ames data, there are several predictors that measure size of the property, such as the total basement size, size of the first floor, the gross living area, and so on. PCA might be an option to represent these potentially redundant variables as a smaller feature set. A recipe step for PCA might look like this:

```{r}
step_pca(matches("(SF$)|)Gr_Liv)"))
```

## Row Sampling Steps

When data has a class imbalance:

* Downsampling the data keeps the minority class and take a random sample of the majority class so that class frequencies are balanced

* Upsampling replicates samples from the minority class the balance the classes. 

* Hybrid methods do a combination of both

The **themis** package has recipe steps that can be used to address class imbalance via subsampling. Other row-based functions include `step_filter()`, `step_sample()`, `step_slice()`, and `step_arrange()`. 

## General Transformations

`step_mutate()` just like the **dplyr** function, can be used to conduct a variety of basic operations to the data like computing the ratio of two variables. 

## Natural Language Processing

The **textrecipes** package can apply natural language processing methods to unstructured data. 

# Skipping Steps for New Data

For simple transformation of the **outcome** columns, we strongly suggest that those operations be conducted outside of the recipe. Each step function has an argument called `skip` that ensures that some operations are only applied to the data given to the model and not new samples. 

# Tidy a `recipe()`

```{r}
ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type +
           Latitude + Longitude,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ Gr_Liv_Area:starts_with("Bldg_Type_")) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)
```

The `tidy()` method gives a summary of the recipe steps:

```{r}
tidy(ames_rec)
```

`id`s can be added to any `step()` function to make it easy to call out a specific step:

```{r}
ames_rec <- 
  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type +
           Latitude + Longitude,
         data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_other(Neighborhood, threshold = 0.01, id = "my_id") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ Gr_Liv_Area:starts_with("Bldg_Type_")) %>% 
  step_ns(Latitude, Longitude, deg_free = 20)

lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(ames_rec)

lm_fit <- fit(lm_wflow, ames_train)

estimated_recipe <- 
  lm_fit %>% 
  extract_recipe(estimated = TRUE)

tidy(estimated_recipe, id = "my_id")
```

Each `tidy()` method returns the relevant information about that step. 

```{r}
tidy(estimated_recipe, number = 3)
```

# Column Roles

When a formula is used with the initial call to `recipe()` it assigns roles to each of the columns depending on which side of the tilde they are on. Those roles are either "predictor" or "outcome". We can also assign new roles. 

For example, in the Ames data, we might want to keep the address column so that we can look up values after making predictions. To do that, we use `add_role()`, `remove_role()`, and `update_role()`. 

```{r}
ames_rec %>% update_role(address, new_role = "street address")
ames_rec
```

